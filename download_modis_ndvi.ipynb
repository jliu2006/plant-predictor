{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c725acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/fun/plant-predictor\n",
      "total 66952\n",
      "-rw-rw-r--.  1 fun fun    35149 Jun 25 15:55 LICENSE\n",
      "-rw-rw-r--.  1 fun fun      141 Jun 25 15:59 README.txt\n",
      "-rw-rw-r--.  1 fun fun   222350 Jun 27 12:52 2d_linear_layer_example.png\n",
      "-rw-rw-r--.  1 fun fun    88307 Jun 27 13:18 3d_linear_layer_example.png\n",
      "-rw-rw-r--.  1 fun fun     1873 Jun 27 13:20 linear layer tutorial.ipynb\n",
      "-rw-rw-r--.  1 fun fun     7862 Jun 27 14:47 patch_embed_attention.ipynb\n",
      "-rw-rw-r--.  1 fun fun  2223493 Jul  1 19:43 download_imerg.ipynb\n",
      "-rw-rw-r--.  1 fun fun  1090420 Jul  2 11:01 CA_wildfires.json\n",
      "-rw-rw-r--.  1 fun fun  1005307 Jul  2 11:02 file_creator.ipynb\n",
      "-rw-rw-r--.  1 fun fun 63470545 Jul  2 15:00 ca_soil_color.tif\n",
      "drwxrwxr-x.  2 fun fun      198 Jul  2 16:01 Soil_CA\n",
      "drwxrwxr-x.  8 fun fun      153 Jul  4 15:58 STTran\n",
      "-rw-rw-r--.  1 fun fun     3087 Jul  4 18:39 sttran_class.py\n",
      "drwx------. 41 fun fun     4096 Jul  5 20:23 ..\n",
      "-rw-rw-r--.  1 fun fun    39043 Jul  5 20:24 download_modis_ndvi.ipynb\n",
      "drwxrwxr-x.  8 fun fun      202 Jul  5 20:30 .git\n",
      "-rw-rw-r--.  1 fun fun    13975 Jul  6 09:32 train_sttran.ipynb\n",
      "-rw-rw-r--.  1 fun fun     2832 Jul  6 10:23 download_imerg_precipitation.ipynb\n",
      "drwxrwxr-x.  2 fun fun     4096 Jul  6 10:53 .ipynb_checkpoints\n",
      "-rw-rw-r--.  1 fun fun      589 Jul  6 10:55 nlp_transformer.ipynb\n",
      "-rw-rw-r--.  1 fun fun   303723 Jul  6 11:00 download_MOD_files.ipynb\n",
      "drwxrwxr-x.  6 fun fun     4096 Jul  6 11:00 .\n"
     ]
    }
   ],
   "source": [
    "#download modis satelite image by date \n",
    "#python3.9 ./download_modis.py\n",
    "from pyhdf.SD import SD, SDC\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from ipynb.fs.full.utils import *\n",
    "import glob\n",
    "from glob import glob\n",
    "import os\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import csv\n",
    "import h5py\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "#import pywt\n",
    "diameter = 5\n",
    "\n",
    "# NDVI: MOD13Q1\n",
    "\n",
    "!pwd\n",
    "!ls -altr\n",
    "!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "263aac4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(folder, filename, datestr):\n",
    "     \n",
    "    username_file = open(\"/home/fun/profile/modis_username.txt\", \"r\")\n",
    "    password_file = open(\"/home/fun/profile/modis_password.txt\", \"r\")\n",
    "    username = username_file.readline()\n",
    "    password = password_file.readline()\n",
    "    \n",
    "    url = generate_modis_url(datestr)\n",
    "    url = url + filename\n",
    "    if len(filename) == 0:\n",
    "        filename = 'fires_index_' + datestr + '.html'\n",
    "    \n",
    "    print ('downloading file ', url)\n",
    "    \n",
    "    r = requests.get(url, auth = (username, password))\n",
    "    if r.status_code == 200:\n",
    "        print ('writing to', folder + filename)\n",
    "        with open(folder + filename, 'wb') as out:\n",
    "            for bits in r.iter_content():\n",
    "                out.write(bits)\n",
    "    else:\n",
    "        print ('download error ', r.status_code)\n",
    "        \n",
    "def parse_html(html_file):\n",
    "    '''\n",
    "    parse html to get file list\n",
    "    '''\n",
    "\n",
    "    with open(html_file, 'r') as input:\n",
    "        soup = BeautifulSoup(input, \"html.parser\").find_all(lambda t: t.name == \"a\" and t.text.startswith('MOD') and t.text.endswith('hdf'))\n",
    "        filelist = []\n",
    "        for it in soup:\n",
    "            filelist.append(it[\"href\"])\n",
    "        return filelist\n",
    "\n",
    "def generate_modis_url(datestr):\n",
    "    '''\n",
    "    compose url using date  'YYYY.MM.DD'\n",
    "    '''\n",
    "    url = 'https://e4ftl01.cr.usgs.gov/MOLT/MOD13Q1.006/'+ datestr[0:4] + '.' + datestr[5:7] + '.'+ datestr[8:10] + '/'\n",
    "    \n",
    "    return url\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e0ebbf9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def download_one_fire(folder):\n",
    "    download_html(folder)\n",
    "    download_hdf(folder)\n",
    "\n",
    "def download_html(folder):\n",
    "    profile = folder + 'profile.json'\n",
    "    f = open(profile)\n",
    "    info = json.load(f)\n",
    "    \n",
    "    start = datetime.datetime.strptime(info['start'], '%Y-%m-%d')\n",
    "    end = datetime.datetime.strptime(info['end'], '%Y-%m-%d')\n",
    "    begin_date = start - timedelta(days=16)\n",
    "    final_date = end + timedelta(days=16)\n",
    "    \n",
    "    it_date = begin_date\n",
    "    while (it_date < final_date):\n",
    "        datestr = it_date.strftime('%Y-%m-%d')\n",
    "        print(datestr)\n",
    "        url = generate_modis_url(datestr)\n",
    "        download_file(folder, \"\", datestr)\n",
    "        try:\n",
    "            filelist = parse_html(folder + 'fires_index_' + datestr + '.html')\n",
    "            it_date = it_date + timedelta(days=16)\n",
    "        except FileNotFoundError:\n",
    "            it_date = it_date + timedelta(days=1)\n",
    "            pass\n",
    "        \n",
    "def download_hdf(folder):\n",
    "    globdirc = folder + '*.html'\n",
    "    for filename in glob(globdirc):\n",
    "        datestr = filename[-15:-5]\n",
    "        filelist = parse_html(filename)\n",
    "        for hdf in filelist:\n",
    "            if ('h08v04' in hdf) or ('h08v05' in hdf):\n",
    "                print('downloading ', hdf, 'to ', folder)\n",
    "                download_file(folder, hdf, datestr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d94dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_one_fire('/home/fun/wildfire_data/August_Complex_includes_Doe_Fire_2020-08-16/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3327760",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folders = glob('/home/fun/wildfire_data/*')\n",
    "for folder in folders:\n",
    "    download_one_fire(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b48ed5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_0 = SD('/home/fun/wildfire_data/August_Complex_includes_Doe_Fire_2020-08-16/MOD13Q1.A2020225.h08v05.006.2020241233111.hdf')\n",
    "hdf = SD('/home/fun/wildfire_data/August_Complex_includes_Doe_Fire_2020-08-16/MOD13Q1.A2020337.h08v05.006.2020358165155.hdf')\n",
    "\n",
    "\n",
    "hdf_dict = hdf.datasets()\n",
    "for idx,sds in enumerate(hdf_dict.keys()):\n",
    "    print ('idx:', idx, '    sds:', sds)\n",
    "  \n",
    "ndvi = hdf.select(0).get()\n",
    "ndvi_0 = hdf_0.select(0).get()\n",
    "\n",
    "\n",
    "plt.imshow(ndvi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c6851e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "h08v04_info = dict([\n",
    "    ('ll_lon', -131.0149),\n",
    "    ('ll_lat', 39.7081),\n",
    "    ('ul_lon', -156.8405),\n",
    "    ('ul_lat', 49.8983),\n",
    "    ('ur_lon', -140.2398),\n",
    "    ('ur_lat', 50.1258),\n",
    "    ('lr_lon', -117.2848),\n",
    "    ('lr_lat', 39.8699),\n",
    "    ('lat_delta', 10),\n",
    "    ('lat_min', 40),\n",
    "    ('lat_max', 50),\n",
    "])\n",
    "\n",
    "h08v05_info = dict([           \n",
    "    ('ll_lon', -115.3696),\n",
    "    ('ll_lat', 29.8308),\n",
    "    ('ul_lon', -130.5407),\n",
    "    ('ul_lat', 40.0000),\n",
    "    ('ur_lon', -117.3606),\n",
    "    ('ur_lat', 40.0852),\n",
    "    ('lr_lon', -103.6998),\n",
    "    ('lr_lat', 29.9063),\n",
    "    ('lat_delta', 10),\n",
    "    ('lat_min', 30),\n",
    "    ('lat_max', 40),\n",
    "])\n",
    "\n",
    "def get_coords(lat, lon, MOD):\n",
    "    lon_index = 0\n",
    "    lat_index = 0\n",
    "    if (h08v05_info['lat_min'] < lat <= h08v05_info['lat_max']): \n",
    "        MOD_lat = MOD + '_h08v05_lat'\n",
    "        MOD_lon = MOD + '_h08v05_lon'\n",
    "    else:\n",
    "        MOD_lat = MOD + '_h08v04_lat'\n",
    "        MOD_lon = MOD + '_h08v04_lon'\n",
    "    while coords[MOD_lat][lat_index][0] > lat:\n",
    "        lat_index += 1\n",
    "    while coords[MOD_lon][lat_index][lon_index] < lon:\n",
    "        lon_index += 1\n",
    "    # print(coords[MOD_lat][lat_index][lon_index], coords[MOD_lon][lat_index][lon_index])\n",
    "    return lat_index, lon_index\n",
    "\n",
    "def get_subimg(lat, lon, radius, hdf_link, MOD):\n",
    "    lat_index, lon_index = get_coords(lat, lon, MOD)\n",
    "    hdf = SD(hdf_link)\n",
    "    ndvi = hdf.select(0).get()\n",
    "    # print(lat_index, lon_index)\n",
    "    subimg = ndvi[lat_index-radius:lat_index+radius, lon_index-radius:lon_index+radius]\n",
    "    return subimg\n",
    "\n",
    "def load_lon_lat(txt):\n",
    "    arr = np.loadtxt(txt, str)\n",
    "    arr = np.char.replace(arr, ',', '')\n",
    "    arr = arr.astype(float)\n",
    "    length = int((arr.shape[0]) ** 0.5)\n",
    "    arr = np.reshape(arr, (length, length))\n",
    "    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e52481bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = dict()\n",
    "txts = glob('/home/fun/wildfire_coords/*.txt')\n",
    "for txt in txts:\n",
    "    name = txt[-22:-4]\n",
    "    arr = load_lon_lat(txt)\n",
    "    coords[name] = arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99f4c602",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def write_imgs(folder, radius):\n",
    "    profile = folder + '/profile.json'\n",
    "    with open(profile) as f:\n",
    "        prof = json.load(f)\n",
    "        lat = prof['info']['latitude']\n",
    "        lon = prof['info']['longitude']\n",
    "    if (h08v05_info['lat_min'] < lat <= h08v05_info['lat_max']): \n",
    "        tile = '*h08v05*'\n",
    "    else:\n",
    "        tile = '*h08v04*'\n",
    "    mod_link = folder + '/' + tile\n",
    "    mods = glob(mod_link)\n",
    "    for mod in mods: \n",
    "        date = datetime.datetime(int(mod[-36:-32]), 1, 1) + datetime.timedelta(days = int(mod[-32:-29])-1)\n",
    "        subimg = get_subimg(lat, lon, radius, mod, mod[-45:-38])\n",
    "        file = folder + '/' + mod[-45:-38] + '_' + date.strftime('%Y-%m-%d') + '.npy'\n",
    "        np.save(file, subimg)\n",
    "        img = plt.imshow(subimg)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c186b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = 100\n",
    "write_imgs('/home/fun/wildfire_data/Saddle_Ridge_Fire_2019-10-10', radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059839d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(ndvi)\n",
    "print(ndvi.size)\n",
    "print(ndvi.shape)\n",
    "\n",
    "ndvi0_sub = ndvi_0[1000:1039,2000:2039]\n",
    "ndvi_sub = ndvi[1000:1039,2000:2039]\n",
    "print(150*40)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "#subplot(r,c) provide the no. of rows and columns\n",
    "f, axarr = plt.subplots(2,1) \n",
    "\n",
    "# use the created array to output your multiple images. In this case I have stacked 4 images vertically\n",
    "axarr[0].imshow(ndvi0_sub)\n",
    "axarr[1].imshow(ndvi_sub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68f8755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "Pixels  = 4800\n",
    "VERTICAL_TILES = 18\n",
    "HORIZONTAL_TILES = 36\n",
    "# EARTH_RADIUS = 6371007.181\n",
    "# EARTH_WIDTH = 2 * math.pi * EARTH_RADIUS\n",
    "\n",
    "\n",
    "#TILE_WIDTH = EARTH_WIDTH / HORIZONTAL_TILES\n",
    "TILE_WIDTH = 1200000\n",
    "TILE_HEIGHT = TILE_WIDTH\n",
    "Pixel_SIZE = TILE_WIDTH / Pixels\n",
    "\n",
    "print('TILE_WIDTH', ':', TILE_WIDTH)\n",
    "print('TILE_HEIGHT', ':', TILE_HEIGHT)\n",
    "print('Pixel_SIZE', ':', Pixel_SIZE)\n",
    "\n",
    "#converting from geographic coordinates\n",
    "def lat_lon_to_modis(lat, lon):\n",
    "    \n",
    "    return int(h), int(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cbc0ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#candidates for presentation:\n",
    "#1)  midsize file = '/home/fun/data/AL162003/10_modis_satellite_20031005.npy'\n",
    "#2) /home/fun/data/AL052001/10_modis_satellite_20010828.npy\n",
    "\n",
    "file ='/home/fun/data/AL052001/10_modis_satellite_20010828.npy'\n",
    "\n",
    "rgb = np.load(file)\n",
    "\n",
    "print (rgb.shape)\n",
    "\n",
    "\n",
    "plt.imshow(rgb, interpolation='nearest', aspect='auto')\n",
    "#plt.imshow(T20)\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "rgb.shape\n",
    "\n",
    "red = rgb[:, :, 0]\n",
    "green = rgb[:, :, 1]\n",
    "blue = rgb[:, :, 2]\n",
    "\n",
    "\n",
    "def neighborRGB(color):\n",
    "    for row in range(len(color)):\n",
    "\n",
    "        found_swath = False\n",
    "        swath_start = 0\n",
    "        len_swath = 0\n",
    "        idx = 0\n",
    "\n",
    "        curr_row = color[row]\n",
    "        \n",
    "        while idx < len(curr_row):\n",
    "            \n",
    "            if found_swath == True:\n",
    "                if curr_row[idx][0] != -2.8672 or curr_row[idx][1] != -2.8672 or curr_row[idx][2] != -2.8672:\n",
    "                    found_swath = False\n",
    "                else:\n",
    "                    len_swath += 1\n",
    "            elif curr_row[idx][0] == -2.8672  and curr_row[idx][1] == -2.8672 and curr_row[idx][2] == -2.8672:\n",
    "                found_swath = True\n",
    "                len_swath = 1\n",
    "                swath_start = idx\n",
    "            idx += 1\n",
    "\n",
    "        existing_vals = []\n",
    "\n",
    "        left_length = max(1,int(len_swath/2))\n",
    "        right_length = max(1,int(len_swath - left_length))\n",
    "        swath_end = swath_start + len_swath + 1\n",
    "        #print(\"left:\",left_length, \"right:\", right_length, \"swath start:\", swath_start)\n",
    "        \n",
    "        extra_right = max(0, swath_end+right_length - len(curr_row))\n",
    "        left_length += extra_right\n",
    "        \n",
    "        extra_left = max(0, left_length - swath_start)\n",
    "        right_length += extra_left\n",
    "\n",
    "        existing_vals = np.append(existing_vals, curr_row[swath_start-left_length:swath_start])\n",
    "        existing_vals = np.append(existing_vals, curr_row[swath_end:swath_end+right_length])\n",
    "        \n",
    "        \n",
    "        for new_row_idx in (idx+1, idx+10):\n",
    "            if new_row_idx >= 0 and new_row_idx < len(color):  # add previous row\n",
    "                new_row = color[new_row_idx]\n",
    "                for i in range(swath_start-left_length, swath_start):\n",
    "                    if i >=0 and i < len(new_row):\n",
    "                        if new_row[i][0] != -2.8672 or new_row[i][1] != -2.8672 or new_row[i][2] != -2.8672:\n",
    "                            existing_vals = np.append(existing_vals, new_row[i])\n",
    "                            \n",
    "                for i in range(swath_end, swath_end+right_length+1):\n",
    "                    if i >=0 and i < len(new_row):\n",
    "                        if new_row[i][0] != -2.8672 or new_row[i][1] != -2.8672 or new_row[i][2] != -2.8672:\n",
    "                            existing_vals = np.append(existing_vals, new_row[i])\n",
    "        \n",
    "    \n",
    "      \n",
    "    \n",
    "        for idx in range(len_swath):\n",
    "            rand_idx = random.randint(0, len(existing_vals)-1)\n",
    "            curr_row[swath_start+idx] = existing_vals[rand_idx]\n",
    "            \n",
    "\n",
    "#neighborRGB(rgb)\n",
    "    \n",
    "\n",
    "\n",
    "rgb_new = np.dstack([red, green, blue])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(rgb_new, interpolation='nearest')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "R_coeffs2 = pywt.dwt2(red, 'bior1.3')\n",
    "G_coeffs2 = pywt.dwt2(green, 'bior1.3')\n",
    "B_coeffs2 = pywt.dwt2(blue, 'bior1.3')\n",
    "\n",
    "titles = ['Approximation', ' Horizontal detail',\n",
    "          'Vertical detail', 'Diagonal detail']\n",
    "\n",
    "R_LL, (R_LH, R_HL, R_HH) = R_coeffs2\n",
    "G_LL, (G_LH, G_HL, G_HH) = G_coeffs2\n",
    "B_LL, (B_LH, B_HL, B_HH) = B_coeffs2\n",
    "\n",
    "\n",
    "def get_circluar_mask(arrlen, cx, cy, r1, r2):\n",
    "    x = np.arange(0, arrlen)\n",
    "    y = np.arange(0, arrlen)\n",
    "    arr = np.zeros((y.size, x.size))\n",
    "    # The two lines below could be merged, but I stored the mask\n",
    "    # for code clarity.\n",
    "    mask = (x[np.newaxis,:]-cx)**2 + (y[:,np.newaxis]-cy)**2 < r1**2\n",
    "    mask2 = (x[np.newaxis,:]-cx)**2 + (y[:,np.newaxis]-cy)**2 < r2**2\n",
    "    arr[mask2] = 1.\n",
    "    arr[mask] = 0.\n",
    "    \n",
    "    # This plot shows that only within the circle the value is set to 123.\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.pcolormesh(x, y, arr)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    return arr\n",
    "\n",
    "def get_circlar_var(inner, outer, arr):\n",
    "    \n",
    "    mask_20th_8th = get_circluar_mask(len(arr[0]), len(arr[0])/2,len(arr[0])/2, len(arr[0])/inner,  len(arr[0])/outer)\n",
    "    \n",
    "    mask_arr = mask_20th_8th.flatten()\n",
    "    val = arr.flatten()\n",
    "    \n",
    "    subset = []\n",
    "    for i in range(0, len(val)):\n",
    "        if mask_arr[i]:\n",
    "            subset.append(val[i])\n",
    "    \n",
    "    return np.var(subset)\n",
    "\n",
    "    \n",
    "print (get_circlar_var(20, 8, R_LH))\n",
    "print (get_circlar_var(8, 4, R_LH))\n",
    "\n",
    "fig = plt.figure(figsize=(24, 6))\n",
    "for i, a in enumerate([R_LL, R_LH, R_HL, R_HH]):\n",
    "    ax = fig.add_subplot(1, 4, i + 1)\n",
    "    ax.imshow(a)\n",
    "    \n",
    "    ax.set_title(titles[i], fontsize=10)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    \n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(R_LH[80:120, 80:120])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcdb9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e6fcb3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#candidates for presentation:\n",
    "#1)  midsize file = '/home/fun/data/AL162003/10_modis_satellite_20031005.npy'\n",
    "#2) /home/fun/data/AL052001/10_modis_satellite_20010828.npy\n",
    "\n",
    "# file ='/home/fun/data/AL182012/10_modis_satellite_20121023.npy'\n",
    "\n",
    "# rgb = np.load(file)\n",
    "\n",
    "\n",
    "# plt.imshow(rgb, interpolation='nearest', aspect='auto')\n",
    "# #plt.imshow(T20)\n",
    "\n",
    "# #plt.show()\n",
    "\n",
    "# rgb.shape\n",
    "\n",
    "# red = rgb[:, :, 0]\n",
    "# green = rgb[:, :, 1]\n",
    "# blue = rgb[:, :, 2]\n",
    "\n",
    "\n",
    "def neighborRGB(color):\n",
    "    for row in range(len(color)):\n",
    "\n",
    "        found_swath = False\n",
    "        swath_start = 0\n",
    "        len_swath = 0\n",
    "        idx = 0\n",
    "\n",
    "        curr_row = color[row]\n",
    "        \n",
    "        while idx < len(curr_row):\n",
    "            \n",
    "            if found_swath == True:\n",
    "                if curr_row[idx][0] != -2.8672 or curr_row[idx][1] != -2.8672 or curr_row[idx][2] != -2.8672:\n",
    "                    found_swath = False\n",
    "                else:\n",
    "                    len_swath += 1\n",
    "            elif curr_row[idx][0] == -2.8672  and curr_row[idx][1] == -2.8672 and curr_row[idx][2] == -2.8672:\n",
    "                found_swath = True\n",
    "                len_swath = 1\n",
    "                swath_start = idx\n",
    "            idx += 1\n",
    "\n",
    "        existing_vals = []\n",
    "\n",
    "        left_length = max(1,int(len_swath/2))\n",
    "        right_length = max(1,int(len_swath - left_length))\n",
    "        swath_end = swath_start + len_swath + 1\n",
    "        #print(\"left:\",left_length, \"right:\", right_length, \"swath start:\", swath_start)\n",
    "        \n",
    "        extra_right = max(0, swath_end+right_length - len(curr_row))\n",
    "        left_length += extra_right\n",
    "        \n",
    "        extra_left = max(0, left_length - swath_start)\n",
    "        right_length += extra_left\n",
    "\n",
    "        existing_vals = np.append(existing_vals, curr_row[swath_start-left_length:swath_start])\n",
    "        existing_vals = np.append(existing_vals, curr_row[swath_end:swath_end+right_length])\n",
    "        \n",
    "        \n",
    "        for new_row_idx in (idx+1, idx+10):\n",
    "            if new_row_idx >= 0 and new_row_idx < len(color):  # add previous row\n",
    "                new_row = color[new_row_idx]\n",
    "                for i in range(swath_start-left_length, swath_start):\n",
    "                    if i >=0 and i < len(new_row):\n",
    "                        if new_row[i][0] != -2.8672 or new_row[i][1] != -2.8672 or new_row[i][2] != -2.8672:\n",
    "                            existing_vals = np.append(existing_vals, new_row[i])\n",
    "                            \n",
    "                for i in range(swath_end, swath_end+right_length+1):\n",
    "                    if i >=0 and i < len(new_row):\n",
    "                        if new_row[i][0] != -2.8672 or new_row[i][1] != -2.8672 or new_row[i][2] != -2.8672:\n",
    "                            existing_vals = np.append(existing_vals, new_row[i])\n",
    "        \n",
    "    \n",
    "      \n",
    "    \n",
    "        for idx in range(len_swath):\n",
    "            rand_idx = random.randint(0, len(existing_vals)-1)\n",
    "            curr_row[swath_start+idx] = existing_vals[rand_idx]\n",
    "            \n",
    "\n",
    "#neighborRGB(rgb)\n",
    "    \n",
    "\n",
    "\n",
    "# rgb_array = np.dstack([red, green, blue])\n",
    "\n",
    "\n",
    "# rgb_array = ((rgb_array * 10000 + 100) / 66.66)*1.5\n",
    "\n",
    "\n",
    "# rgb_array = rgb_array.astype(int)\n",
    "\n",
    "# rgb_array[rgb_array < 0] = 0\n",
    "# rgb_array[rgb_array > 255] = 255\n",
    "\n",
    "# red = rgb_array[:, :, 0]\n",
    "# green = rgb_array[:, :, 1]\n",
    "# blue = rgb_array[:, :, 2]\n",
    "\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(8, 8))\n",
    "# ax.imshow(rgb_array, interpolation='nearest')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# fig.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# R_coeffs2 = pywt.dwt2(red, 'bior1.3')\n",
    "# G_coeffs2 = pywt.dwt2(green, 'bior1.3')\n",
    "# B_coeffs2 = pywt.dwt2(blue, 'bior1.3')\n",
    "\n",
    "# titles = ['Approximation', ' Horizontal detail',\n",
    "#           'Vertical detail', 'Diagonal detail']\n",
    "\n",
    "# R_LL, (R_LH, R_HL, R_HH) = R_coeffs2\n",
    "# G_LL, (G_LH, G_HL, G_HH) = G_coeffs2\n",
    "# B_LL, (B_LH, B_HL, B_HH) = B_coeffs2\n",
    "\n",
    "# def getsquare(start, end, arr):\n",
    "#     print(np.var(arr[start:end, start:end].flatten()))\n",
    "\n",
    "# print (R_LH[75:125, 75:125])\n",
    "# getsquare(0, 50, R_LH)\n",
    "# getsquare(50, 100, R_LH)\n",
    "# getsquare(75, 125, R_LH)\n",
    "# getsquare(60, 140, R_LH)\n",
    "\n",
    "# fig = plt.figure(figsize=(24, 6))\n",
    "# for i, a in enumerate([R_LL, R_LH, R_HL, R_HH]):\n",
    "#     ax = fig.add_subplot(1, 4, i + 1)\n",
    "#     ax.imshow(a, interpolation=\"nearest\", cmap=plt.cm.gray)\n",
    "    \n",
    "#     ax.set_title(titles[i], fontsize=10)\n",
    "#     ax.set_xticks([])\n",
    "#     ax.set_yticks([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91682854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "# This is the size of our encoded representations\n",
    "encoding_dim = 40000  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# This is our input image\n",
    "input_img = keras.Input(shape=(40000,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = layers.Dense(200, activation='sigmoid')(encoded)\n",
    "\n",
    "# This model maps an input to its reconstruction\n",
    "autoencoder = keras.Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbca3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = keras.Model(input_img, encoded)\n",
    "\n",
    "encoded_input = keras.Input(shape=(encoding_dim,))\n",
    "# Retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# Create the decoder model\n",
    "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46145163",
   "metadata": {},
   "outputs": [],
   "source": [
    "red = red.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aafc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer=\"adam\"\n",
    "                    , loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.fit(red, red,\n",
    "                epochs=50,\n",
    "                validation_data=(rgb, rgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2bcbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf = SD('/home/fun/data/AL182012/MOD09CMG.A2012298.006.2015250045544.hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a47ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimeIndex(lon, lat):\n",
    "    n = 3600\n",
    "    m = 7200\n",
    "\n",
    "    interval = 180.0 / n\n",
    "\n",
    "    lat_index = int((90 - lat) / interval)\n",
    "    long_index = int((lon + 180) / interval)\n",
    "    \n",
    "    return long_index, lat_index\n",
    "\n",
    "def getTgtArea(global_map, lon, lat, radius):\n",
    "    n = 3600\n",
    "    m = 7200\n",
    "\n",
    "    interval = 180.0 / n\n",
    "\n",
    "    lat_index = int((90 - lat) / interval)\n",
    "    long_index = int((lon + 180) / interval)\n",
    "\n",
    "    n_radius = int(radius / interval)\n",
    "\n",
    "    return global_map[lat_index - n_radius:lat_index + n_radius, long_index - n_radius:long_index + n_radius]\n",
    "\n",
    "#def interpolateLocation(day, path, time_array):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb4407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in hdf.datasets():\n",
    "    print (it)\n",
    "\n",
    "time = hdf.select('Coarse Resolution Granule Time').get()\n",
    "\n",
    "R = hdf.select('Coarse Resolution Surface Reflectance Band 1').get()\n",
    "B = hdf.select('Coarse Resolution Surface Reflectance Band 3').get()\n",
    "G = hdf.select('Coarse Resolution Surface Reflectance Band 4').get()\n",
    "\n",
    "R_true = R * 0.0001\n",
    "G_true = G * 0.0001\n",
    "B_true = B * 0.0001\n",
    "\n",
    "rgb = np.dstack([R_true, G_true, B_true])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91a3478",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '/home/fun/data/AL182012' + '/profile.json'\n",
    "f = open(name)\n",
    "profile = json.load(f)\n",
    "paths = profile['path']\n",
    "\n",
    "select_path = paths[9]\n",
    "\n",
    "print(select_path)\n",
    "\n",
    "lat = str(select_path['lt'])\n",
    "lon = str(select_path['lg'])\n",
    "lom = -1 if lon[-1] == 'W' else 1\n",
    "\n",
    "lat = float(lat[:-1])\n",
    "lon = float(lon[:-1])\n",
    "\n",
    "print(lat, lon)\n",
    "\n",
    "lon_index, lat_index, = getTimeIndex(lon, lat)\n",
    "\n",
    "print(lon_index, lat_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a4b364",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_time = (time[lon_index, lat_index])/60\n",
    "selected_time # hours after 00:00, 12 AM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aea8acc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "time_array = getTgtArea(time, lon, lat, 12.5)\n",
    "selected_rgb = getTgtArea(rgb, lon, lat, 12.5)\n",
    "plt.imshow(time_array)\n",
    "plt.show()\n",
    "plt.imshow(selected_rgb)\n",
    "plt.show()\n",
    "\n",
    "# swath gaps come from missing satellite coverage, resulting in non-smooth time differences\n",
    "\n",
    "print(selected_time)\n",
    "time_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c687fda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNearestIndex(array, value):\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "def getScaleFactor(small_time, large_time, target_time): # coefficient of multiplication for lin interpolation\n",
    "    delta_time = large_time - small_time\n",
    "    delta_target = target_time - small_time\n",
    "    scale_factor = delta_target/delta_time\n",
    "    return scale_factor\n",
    "\n",
    "def coordSTRtoFLOAT(coords): # called in linearInterpolation, shape (2,), lat first then lon\n",
    "    lat = str(coords[0])\n",
    "    lon = str(coords[1])\n",
    "    lom = -1 if lon[-1] == 'W' else 1\n",
    "\n",
    "    lat = float(lat[:-1])\n",
    "    lon = float(lon[:-1])\n",
    "    lon = lon * lom\n",
    "    \n",
    "    return lat, lon\n",
    "\n",
    "\n",
    "def linearCalculation(scale_factor, small_coords, large_coords): # coords passed as shape (2,)\n",
    "\n",
    "    sm_lat, sm_lon = coordSTRtoFLOAT(small_coords)\n",
    "    lg_lat, lg_lon = coordSTRtoFLOAT(large_coords)\n",
    "    \n",
    "    delta_lat = lg_lat - sm_lat\n",
    "    delta_lon = lg_lon - sm_lon\n",
    "    \n",
    "    scale_lat = delta_lat * scale_factor\n",
    "    scale_lon = delta_lon * scale_factor\n",
    "    \n",
    "    interp_lat = scale_lat + sm_lat\n",
    "    interp_lon = scale_lon + sm_lon\n",
    "    \n",
    "    return interp_lat, interp_lon\n",
    "\n",
    "def wrappedLinearInterpolation(paths, day, selected_time):\n",
    "    early_times = []\n",
    "    early_coords = []\n",
    "    late_times = []\n",
    "    late_coords = []\n",
    "    for path in paths:\n",
    "\n",
    "        if path['date'] == int(day):\n",
    "            path_time_hour = float(path['time'])/60\n",
    "            if path_time_hour <= selected_time:\n",
    "                early_times = np.append(early_times, path_time_hour)\n",
    "                early_coords = np.append(early_coords, (path['lt'], path['lg']))\n",
    "                early_coords = early_coords.reshape(int(len(early_coords)/2), 2)\n",
    "            else:\n",
    "                late_times = np.append(late_times, path_time_hour)\n",
    "                late_coords = np.append(late_coords, (path['lt'], path['lg']))\n",
    "                late_coords = late_coords.reshape(int(len(late_coords)/2), 2)\n",
    "\n",
    "    early_index = getNearestIndex(early_times, selected_time)\n",
    "    late_index = getNearestIndex(late_times, selected_time)\n",
    "\n",
    "    scale_factor = getScaleFactor(early_times[early_index], late_times[late_index], selected_time)\n",
    "\n",
    "    new_lon, new_lat = linearCalculation(scale_factor, early_coords[early_index], late_coords[late_index])\n",
    "\n",
    "    return new_lon, new_lat\n",
    "\n",
    "def getClosestTime(profile, time_array, day):\n",
    "    paths = profile['path']\n",
    "    paths_in_day = []\n",
    "    time_diffs = []\n",
    "    for path in paths:\n",
    "        if path['date'] == int(day):\n",
    "            paths_in_day = np.append(paths_in_day, path)\n",
    "    \n",
    "    for path in paths_in_day:\n",
    "        # get lt, lg, pass through getTimeIndex(lon, lat)\n",
    "        # get time[new_lat, new_lon], append to time_diffs\n",
    "        # time_diffs = time_diffs/60\n",
    "        # idx = getNearestIndex(time_diffs, early_time)\n",
    "        # if time_diffs[idx] - early_time >= (late_time - early_time)/2:\n",
    "            # ...\n",
    "        # \n",
    "    getNearestIndex(array, value)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05803f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_in_day = []\n",
    "for path in paths:\n",
    "    if path['date'] == int(20121024):\n",
    "        day = np.append(day, path)\n",
    "        \n",
    "        \n",
    "day[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ef0eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lon, new_lat = wrappedLinearInterpolation(paths, '20121024', selected_time)\n",
    "\n",
    "print(new_lon, new_lat)\n",
    "\n",
    "new_rgb = getTgtArea(rgb, new_lon, new_lat, 12.5)\n",
    "\n",
    "plt.imshow(new_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7d9e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_indices = getTimeIndex(interpolated[1], interpolated[0])\n",
    "print(interp_indices)\n",
    "new_time = time[interp_indices[0], interp_indices[1]]\n",
    "print(new_time/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535c984b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# HURRICANE IDA (AL092021) ON AUGUST 29TH (20210829) AFTER HCI\n",
    "file ='/home/fun/data/AL092021/10_modis_satellite_20210829.npy'\n",
    "\n",
    "rgb = np.load(file)\n",
    "\n",
    "R_true = rgb[:, :, 0]\n",
    "B_true = rgb[:, :, 2]\n",
    "G_true = rgb[:, :, 3]\n",
    "\n",
    "R_true = R_true * 0.00010\n",
    "G_true = G_true * 0.00010\n",
    "B_true = B_true * 0.00010\n",
    "\n",
    "rgb_display = np.dstack([R_true, G_true, B_true])\n",
    "    \n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "fig.tight_layout()\n",
    "plt.imshow(rgb_display, interpolation='nearest', aspect='auto')\n",
    "\n",
    "# rgb = ((rgb * 10000 + 100) / 66.66)*1.5\n",
    "\n",
    "\n",
    "# rgb = rgb.astype(int)\n",
    "\n",
    "# rgb[rgb < 0] = 0\n",
    "# rgb[rgb > 255] = 255\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# plt.imshow(rgb, interpolation='nearest', aspect='auto')\n",
    "# #plt.imshow(T20)\n",
    "\n",
    "# #plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# red = rgb[:, :, 0]\n",
    "# green = rgb[:, :, 1]\n",
    "# blue = rgb[:, :, 2]\n",
    "\n",
    "\n",
    "# print (green.max(), red.max(), blue.max())\n",
    "# print (green.min(), red.min(), blue.min())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132ad10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HURRICANE IDA (AL092021) ON AUGUST 29TH (20210829) AFTER HCI\n",
    "file ='/home/fun/data/AL092021/10_modis_satellite_20210829.npy'\n",
    "\n",
    "rgb = np.load(file)\n",
    "\n",
    "R_true = rgb[:, :, 0]\n",
    "B_true = rgb[:, :, 2]\n",
    "G_true = rgb[:, :, 3]\n",
    "\n",
    "R_true = R_true * 0.00010\n",
    "G_true = G_true * 0.00010\n",
    "B_true = B_true * 0.00010\n",
    "\n",
    "rgb_display = np.dstack([R_true, G_true, B_true])\n",
    "    \n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "fig.tight_layout()\n",
    "plt.imshow(rgb_display, interpolation='nearest', aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcd1062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HURRICANE TEDDY ON SEPTEMBER 17TH 2020 FOR THE DSGF ALGO\n",
    "\n",
    "file ='/home/fun/data/AL202020/10_modis_satellite_20200917.npy'\n",
    "\n",
    "rgb = np.load(file)\n",
    "\n",
    "R_true = rgb[:, :, 0]\n",
    "B_true = rgb[:, :, 2]\n",
    "G_true = rgb[:, :, 3]\n",
    "\n",
    "R_true = R_true * 0.00010\n",
    "G_true = G_true * 0.00010\n",
    "B_true = B_true * 0.00010\n",
    "\n",
    "rgb_display = np.dstack([R_true, G_true, B_true])\n",
    "    \n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "fig.tight_layout()\n",
    "plt.imshow(rgb_display, interpolation='nearest', aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96f9da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HURRICANE SAM ON OCTOBER 1ST 2021 FOR THE HCI ALGO\n",
    "file ='/home/fun/data/AL182021/10_modis_satellite_20211001.npy'\n",
    "\n",
    "rgb = np.load(file)\n",
    "\n",
    "R_true = rgb[:, :, 0]\n",
    "B_true = rgb[:, :, 2]\n",
    "G_true = rgb[:, :, 3]\n",
    "\n",
    "R_true = R_true * 0.00011\n",
    "G_true = G_true * 0.00011\n",
    "B_true = B_true * 0.00011\n",
    "\n",
    "rgb_display = np.dstack([R_true, G_true, B_true])\n",
    "    \n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "fig.tight_layout()\n",
    "plt.imshow(rgb_display, interpolation='nearest', aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4044ab80",
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_test = np.load('/home/fun/data/AL092021/noaa_sst_20210829.npy')\n",
    "sst_test = sst_test.reshape(200, 200)\n",
    "\n",
    "print(sst_test)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "shw = ax.imshow(sst_test, vmin = -10, vmax = 30)\n",
    "bar = plt.colorbar(shw)\n",
    "  \n",
    "# show plot with labels\n",
    "bar.set_label('Sea Skin Temperature (C)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92343279",
   "metadata": {},
   "outputs": [],
   "source": [
    "imerg_test = np.load('/home/fun/data/AL092021/imerg_precipitation_20210829_0000.npy')\n",
    "imerg_test = imerg_test.reshape(200, 200)\n",
    "print(imerg_test)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "shw = ax.imshow(imerg_test, vmin = 0, vmax = 20)\n",
    "bar = plt.colorbar(shw)\n",
    "  \n",
    "# show plot with labels\n",
    "bar.set_label('Amount of Precipitation (mm/hr)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452158e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
